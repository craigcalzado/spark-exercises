{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyspark\n",
    "from pydataset import data\n",
    "from pyspark.sql.functions import sum, mean, concat, lit, regexp_extract, regexp_replace, when\n",
    "from vega_datasets import data\n",
    "from pyspark.sql.functions import month, year, quarter\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a spark data frame that contains your favorite programming languages.\n",
    "\n",
    "- The name of the column should be language\n",
    "\n",
    "- View the schema of the dataframe\n",
    "\n",
    "- Output the shape of the dataframe\n",
    "\n",
    "- Show the first 5 records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/18 11:02:01 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language\n",
       "0   Python\n",
       "1    Scala\n",
       "2        R\n",
       "3     Java\n",
       "4      C++"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(456)\n",
    "\n",
    "# Create a spark data frame that contains your favorite programming languages.\n",
    "lang_df = pd.DataFrame({\"language\": [\"Python\", \"Scala\", \"R\", \"Java\", \"C++\", \"Haskell\", \"Clojure\"]})\n",
    "lang_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(lang_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- language: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# View the schema of the dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output the shape of the dataframe\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|language|\n",
      "+--------+\n",
      "|  Python|\n",
      "|   Scala|\n",
      "|       R|\n",
      "|    Java|\n",
      "|     C++|\n",
      "+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the first 5 records in the dataframe\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the mpg dataset as a spark dataframe.\n",
    "\n",
    "Create 1 column of output that contains a message like the one below:\n",
    "\n",
    "\n",
    "The 1999 audi a4 has a 4 cylinder engine.\n",
    "For each vehicle.\n",
    "\n",
    "Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the mpg dataset as a spark dataframe.\n",
    "from pydataset import data\n",
    "\n",
    "mpg = spark.createDataFrame(data(\"mpg\"))\n",
    "mpg.show(5)\n",
    "# Load the mpg dataset as a spark dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+\n",
      "|vehicle_cylinder_desc                                         |\n",
      "+--------------------------------------------------------------+\n",
      "|The 1999 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 4 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 1999 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 2008 audi a4 has a 6 cylinder engine.                     |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 4 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 1999 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a4 quattro has a 6 cylinder engine.             |\n",
      "|The 1999 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 6 cylinder engine.             |\n",
      "|The 2008 audi a6 quattro has a 8 cylinder engine.             |\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine.|\n",
      "|The 2008 chevrolet c1500 suburban 2wd has a 8 cylinder engine.|\n",
      "+--------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create 1 column of output that contains a message like the one below:\n",
    "# 'The 1999 audi a4 has a 4 cylinder engine.'\n",
    "# For each vehicle once.\n",
    "\n",
    "mpg.select(\n",
    "    concat(\n",
    "        lit(\"The \"),\n",
    "        col(\"year\"),\n",
    "        lit(\" \"),\n",
    "        col(\"manufacturer\"),\n",
    "        lit(\" \"),\n",
    "        col(\"model\"),\n",
    "        lit(\" has a \"),\n",
    "        col(\"cyl\"),\n",
    "        lit(\" cylinder engine.\"),\n",
    "    ).alias(\"vehicle_cylinder_desc\")\n",
    ").show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the trans column so that it only contains either manual or auto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+----------+-----------------+\n",
      "|manufacturer|model|displ|year|cyl|     trans|drv|cty|hwy| fl|  class|     trans|transformed_trans|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+----------+-----------------+\n",
      "|        audi|   a4|  1.8|1999|  4|  auto(l5)|  f| 18| 29|  p|compact|  auto(l5)|             auto|\n",
      "|        audi|   a4|  1.8|1999|  4|manual(m5)|  f| 21| 29|  p|compact|manual(m5)|           manual|\n",
      "|        audi|   a4|  2.0|2008|  4|manual(m6)|  f| 20| 31|  p|compact|manual(m6)|           manual|\n",
      "|        audi|   a4|  2.0|2008|  4|  auto(av)|  f| 21| 30|  p|compact|  auto(av)|             auto|\n",
      "|        audi|   a4|  2.8|1999|  6|  auto(l5)|  f| 16| 26|  p|compact|  auto(l5)|             auto|\n",
      "+------------+-----+-----+----+---+----------+---+---+---+---+-------+----------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Transform the trans column so that it only contains either manual or auto.\n",
    "mpg = mpg.select(\"*\", mpg.trans, regexp_extract(\"trans\", r\"(.\\w+)\", 1).alias('transformed_trans'))\n",
    "mpg.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the tips dataset as a spark dataframe.\n",
    "\n",
    "What percentage of observations are smokers?\n",
    "\n",
    "Create a column that contains the tip percentage\n",
    "Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tips dataset\n",
    "tips = spark.createDataFrame(data('tips'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|\n",
      "+----------+----+------+------+---+------+----+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|\n",
      "+----------+----+------+------+---+------+----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# view data\n",
    "tips.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What percentage of observations are smokers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.createOrReplaceTempView(\"tips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|       pct_smokers|\n",
      "+------------------+\n",
      "|38.114754098360656|\n",
      "+------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# run SQL query using spark\n",
    "spark.sql(\n",
    "    \"\"\"\n",
    "SELECT ((SELECT COUNT(smoker)\n",
    "FROM tips\n",
    "WHERE smoker = 'Yes') / \n",
    "(SELECT COUNT(smoker)\n",
    "FROM tips)*100) as pct_smokers\n",
    "FROM tips\n",
    "\"\"\"\n",
    ").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column that contains the tip percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create column that contains the tip percentage\n",
    "# calculate tip percent\n",
    "col = (tips.tip / tips.total_bill) * 100\n",
    "# create new column\n",
    "tip_df = tips.select('*', col.alias('tip_per'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|total_bill| tip|   sex|smoker|day|  time|size|           tip_per|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "|     16.99|1.01|Female|    No|Sun|Dinner|   2|5.9446733372572105|\n",
      "|     10.34|1.66|  Male|    No|Sun|Dinner|   3|16.054158607350097|\n",
      "|     21.01| 3.5|  Male|    No|Sun|Dinner|   3|16.658733936220845|\n",
      "+----------+----+------+------+---+------+----+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tip_df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the average tip percentage for each combination of sex and smoker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+------------------+\n",
      "|   sex|                No|               Yes|\n",
      "+------+------------------+------------------+\n",
      "|Female|15.692097076918358| 18.21503526994103|\n",
      "|  Male| 16.06687151291298|15.277117520248513|\n",
      "+------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use groupby to find the average tip for sex and smoker\n",
    "tip_df.groupby(\"sex\").pivot('smoker').mean('tip_per').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the seattle weather dataset referenced in the lesson to answer the questions below.\n",
    "\n",
    "- Convert the temperatures to fahrenheit.\n",
    "\n",
    "- Which month has the most rain, on average?\n",
    "\n",
    "- Which year was the windiest?\n",
    "\n",
    "- What is the most frequent type of weather in January?\n",
    "\n",
    "- What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "\n",
    "- What percentage of days were rainy in q3 of 2015?\n",
    "\n",
    "- For each year, find what percentage of days it rained (had non-zero precipitation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+--------+--------+----+-------+\n",
      "|      date|precipitation|temp_max|temp_min|wind|weather|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "|2012-01-01|          0.0|    12.8|     5.0| 4.7|drizzle|\n",
      "|2012-01-02|         10.9|    10.6|     2.8| 4.5|   rain|\n",
      "|2012-01-03|          0.8|    11.7|     7.2| 2.3|   rain|\n",
      "|2012-01-04|         20.3|    12.2|     5.6| 4.7|   rain|\n",
      "|2012-01-05|          1.3|     8.9|     2.8| 6.1|   rain|\n",
      "|2012-01-06|          2.5|     4.4|     2.2| 2.2|   rain|\n",
      "+----------+-------------+--------+--------+----+-------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# acuire data from vega_datasets\n",
    "\n",
    "from vega_datasets import data\n",
    "\n",
    "weather = data.seattle_weather().assign(date=lambda df: df.date.astype(str))\n",
    "weather = spark.createDataFrame(weather)\n",
    "weather.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------+----+-------+----------+----------+\n",
      "|      date|precipitation|wind|weather|temp_max_F|temp_min_F|\n",
      "+----------+-------------+----+-------+----------+----------+\n",
      "|2012-01-01|          0.0| 4.7|drizzle|     55.04|      41.0|\n",
      "|2012-01-02|         10.9| 4.5|   rain|     51.08|     37.04|\n",
      "|2012-01-03|          0.8| 2.3|   rain|     53.06|     44.96|\n",
      "|2012-01-04|         20.3| 4.7|   rain|     53.96|     42.08|\n",
      "|2012-01-05|          1.3| 6.1|   rain|     48.02|     37.04|\n",
      "+----------+-------------+----+-------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Convert the temperatures to fahrenheit.\n",
    "weather = weather.withColumn('temp_max_F', ((weather.temp_max.cast('double') * 9 / 5) + 32)).drop('temp_max')\n",
    "weather = weather.withColumn('temp_min_F', ((weather.temp_min.cast('double') * 9 / 5) + 32)).drop('temp_min')\n",
    "weather.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|month|         avg_rain|\n",
      "+-----+-----------------+\n",
      "|   11|5.354166666666667|\n",
      "+-----+-----------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Which month has the most rain, on average?\n",
    "(weather.withColumn('month', month('date'))\n",
    "    .groupBy('month')\n",
    "    .agg(mean('precipitation').alias('avg_rain'))\n",
    "    .sort(desc('avg_rain'))\n",
    "    .show(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2012, total_wind=1244.6999999999998),\n",
       " Row(year=2014, total_wind=1236.5000000000005),\n",
       " Row(year=2015, total_wind=1153.3),\n",
       " Row(year=2013, total_wind=1100.8000000000002)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Which year was the windiest?\n",
    "(\n",
    "    weather.withColumn(\"year\", year(\"date\"))\n",
    "    .groupBy(\"year\")\n",
    "    .agg(sum(\"wind\").alias(\"total_wind\"))\n",
    "    .sort(desc(\"total_wind\"))\n",
    "    .head(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|weather|count|\n",
      "+-------+-----+\n",
      "|    fog|   38|\n",
      "|   rain|   35|\n",
      "|    sun|   33|\n",
      "|drizzle|   10|\n",
      "|   snow|    8|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the most frequent type of weather in January?\n",
    "(\n",
    "    weather.withColumn(\"month\", month(\"date\"))\n",
    "    .filter(column(\"month\") == 1)\n",
    "    .groupBy(\"weather\")\n",
    "    .count()\n",
    "    .sort(desc(\"count\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----------------+\n",
      "|average_high_temp| average_low_temp|\n",
      "+-----------------+-----------------+\n",
      "|80.29192307692308|57.52884615384615|\n",
      "+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What is the average high and low temperature on sunny days in July in 2013 and 2014?\n",
    "(\n",
    "    weather.filter(month(\"date\") == 7)\n",
    "    .filter(year(\"date\") > 2012)\n",
    "    .filter(year(\"date\") < 2015)\n",
    "    .filter(column(\"weather\") == lit(\"sun\"))\n",
    "    .agg(\n",
    "        avg(\"temp_max_F\").alias(\"average_high_temp\"),\n",
    "        avg(\"temp_min_F\").alias(\"average_low_temp\"),\n",
    "    )\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "| (avg(rain) * 100)|\n",
      "+------------------+\n",
      "|2.1739130434782608|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# What percentage of days were rainy in q3 of 2015?\n",
    "(\n",
    "    weather.filter(year(\"date\") == 2015)\n",
    "    .filter(quarter(\"date\") == 3)\n",
    "    .select(when(column(\"weather\") == \"rain\", 1).otherwise(0).alias(\"rain\"))\n",
    "    .agg(mean(\"rain\")*100)\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-------------------+\n",
      "|year|          avg(rain)|\n",
      "+----+-------------------+\n",
      "|2012|0.48360655737704916|\n",
      "|2013|0.41643835616438357|\n",
      "|2014|  0.410958904109589|\n",
      "|2015|0.39452054794520547|\n",
      "+----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# For each year, find what percentage of days it rained (had non-zero precipitation).\n",
    "(\n",
    "    weather.withColumn(\"year\", year(\"date\"))\n",
    "    .select(when(column(\"precipitation\") > 0, 1).otherwise(0).alias(\"rain\"), \"year\")\n",
    "    .groupby(\"year\")\n",
    "    .agg(mean(\"rain\"))\n",
    "    .show()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3067ead486e059ec00ffe7555bdb889e6e264a24dc711bf108106cc7baee8d5d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
